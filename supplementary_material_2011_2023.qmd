---
title: "A latent trajectory analysis in glycemic control and diabetic retinopathy screening coverage 2011-2023: A municipality-level study"
subtitle: Supplementary Material
editor: visual
tbl-cap-location: top
#number-sections: true
format:
  html:
    toc: true
    toc_float: true
    toc_depth: 2
    number_sections: true
    code_folding: hide
    theme: readable
  pdf:
    number-sections: true
    colorlinks: true
    keeptex: true
    include-in-header: 
      text: |
        \usepackage{booktabs}
        \usepackage{siunitx}
        \newcolumntype{d}{S[
            input-open-uncertainty=,
            input-close-uncertainty=,
            parse-numbers = false,
            table-align-text-pre=false,
            table-align-text-post=false
         ]}
  docx: default
prefer-html: true
date: 'last-modified'
execute:
  echo: false
  warning: false
  error: true
  cache: false
---

```{r}
#| echo: false
#| warning: false

# 📚 Load required libraries
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(purrr)
library(patchwork)
library(tidyverse)
library(knitr)
library(kableExtra)
library(ggtext)
library(Cairo)
library(extrafont)
library(hrbrthemes)
library(directlabels)
library(ggrepel)
library(readxl)
library(scales)
library(ggsci)
library(lcmm)
library(MixAll)
library(kml)
library(traj)
library(lmerTest)
library(plyr)
library(psych)
library(fpc)
library(mclust)
library(rcompanion)
library(gridExtra)
library(tidyLPA)
library(MASS)
library(broom)
library(skimr)
library(gtExtras)
library(pander)
library(BayesFactor)
library(modelsummary)
library(gt)
library(gtsummary)
library(survival)
library(xtable)
library(htmltools)
library(tibble)
library(LCTMtools)
library(grid)
library(rlang)
library(lmtest)
library(quarto)
library(Hmisc)
library(nnet)
library(stats)



options(scipen=10000000)
```

**Rolando Silva-Jorquera^1^, Kasim Allel^2^, Hassan Haghparast-Bidgoli^1^, Paul Nderitu^3^, Claudio Zett^4^, Abraham Olvera-Barrios^5,6^, Alasdair Warwick^5,6,7^**

^1^Institute for Global Health, University College London, UK.

^2^Nuffield Department of Population Health, University of Oxford, UK

^3^Faculty of Life Sciences and Medicine, King’s College London, UK

^4^Pontificia Universidad Católica de Valparaíso, Chile

^5^NIHR Biomedical Research Centre at Moorfields Eye Hospital NHS Foundation Trust

^6^Institute of Ophthalmology, University College London, UK

^7^Institute of Cardiovascular Science, University College London, UK

------------------------------------------------------------------------

```{r}
#| message: false
#| warning: false
#| tbl-align: left


structure_table <- data.frame(
  Model = LETTERS[1:10],
  Description = c(
    "Linear without random effects with equal variances",
    "Linear without random effects with varying variances",
    "Quadratic without random effects",
    "Cubic without random effects",
    "Linear with random intercept",
    "Linear with random intercept and slope",
    "Quadratic with random intercept and slope",
    "Quadratic with random intercept and slope and proportional variance",
    "Cubic with random intercept and slope",
    "Cubic with random intercept and slope and proportional variance"
  ),
  Interpretation = c(
    "Captures linear trends assuming constant variance across latent classes and no individual-level variability.",
    "Captures linear trends allowing class-specific variances, without accounting for individual-level random effects.",
    "Captures curvilinear (quadratic) trajectories with fixed effects only and shared variance structure.",
    "Captures complex nonlinear (cubic) fixed trends without random effects or variance heterogeneity.",
    "Allows individuals to vary in their baseline levels (intercepts) while modeling linear overall trends.",
    "Accounts for both baseline and slope variability across individuals in modeling linear trends.",
    "Models quadratic trajectories with random effects on both intercept and slope, allowing individual variation.",
    "Same as previous, but allows proportional variance differences across latent classes for more flexibility.",
    "Captures complex cubic trends while accounting for individual variation in intercepts and slopes.",
    "Extends the cubic random effects model by allowing class-specific proportional variance structures."
  ),
  stringsAsFactors = FALSE
)

# View table
structure_table %>% 
  gt::gt() %>%
  tab_header(
    title = md("**Supplementary Table S1. Description of the 10 candidate model structures tested in the LCMM analysis**")) %>% 
  tab_options(
    table.font.size = 10,
    data_row.padding = px(1),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white") %>% 
  tab_source_note(source_note = md(" **Note:** Each model structure was applied across multiple class solutions (1–7 classes) and evaluated using BIC, classification adequacy, and visual interpretability to identify optimal specifications for each outcome and period."))


```

```{r}
#| message: false
#| warning: false
#| tbl-align: left


table_s2 <- tibble::tibble(
  Tool = c(
    "Model Structure",
    "BIC, AIC, LRT",
    "APPA",
    "Odds of Correct Classification (OCC)",
    "Mismatch",
    "Entropy",
    "Relative Entropy",
    "Degrees of Separation",
    "Envelope of Residuals"
  ),
  `Criteria for a good model` = c(
    "—",
    "Lowest BIC/AIC",
    "> 0.70 for each class",
    "> 5.0 for each class",
    "Close to 0",
    "Close to 0",
    "Close to 1 (> 6.0 recommended)",
    "Higher = more separation",
    "Parallel and narrow boundaries"
  ),
  Description = c(
    "COVERAGE_itk = β₀ᵏ + β₁ᵏ·YEAR_it + β₂ᵏ·YEAR_it² + b₀ᵏ + b₁ᵏ·YEAR_it + b₂ᵏ·YEAR_it² + εₜ (Eq. 1)\n→ β: fixed effects; b: random effects; εₜ: error term.\nPr(i in class k) = exp(π_k) / Σ exp(π_l) (Eq. 2)\n→ π_k: class-specific membership parameter.",
    "Likelihood-based tools to evaluate model parsimony and fit.",
    "Average Posterior Probability Assignment;\nmeasures certainty of class membership.",
    "OCC = OCC = (πg * (1 - pg)) / (pg * (1 - πg)) — compares expected vs. actual class membership.",
    "Mismatch = Mismatch = πg - ng/N — difference between predicted and assigned class size.",
    "Entropy = Entropy = – Σi Σg (pig * log(pig)) — global uncertainty across posterior probabilities.",
    "Relative Entropy = 1 – (E / (G * log G)) — standardized measure of classification uncertainty.",
    "Weighted Mahalanobis distance between predicted class means;\nhigher = more distinct classes.",
    "Residual bounds: mean ± SD of residuals;\nnon-parallel/wide bounds suggest heteroscedasticity or poor class separation."
  )
)

gt(table_s2) %>%
  tab_header(
    title = md("**Supplementary Table S2. Model structure and commonly assessment tools used in the LCMM analysis**")
  ) %>%
  tab_source_note(
    md("*DoS and residual envelopes were implemented following Peugh & Fan and Elsensohn et al.*")
  ) %>%
  tab_options(
    table.font.size = 11,
    data_row.padding = px(2),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    column_labels.border.bottom.color = "black"
  ) 



```

```{r}
#| label: Fig-S1
#| fig-align: left
#| fig-width: 10
#| fig-height: 7
#| warning: false



# Paquetes necesarios
library(dplyr)
library(ggplot2)
library(purrr)
library(tidyr)
library(stringr)
library(scales)
library(patchwork)

# 1. Cargar datos
coverage_data <- read.csv("coverage_2011_2023_noq1.csv") %>%
  arrange(comuna2, ano) %>%
  group_by(comuna2) %>%
  mutate(year = row_number()) %>%   # índice seguro
  ungroup() %>%
  mutate(
    id = comuna2,
    drsc = drs_coverage,
    dgcc = dm_coverage
  )


# 2. Cargar modelos
all_models_by_period <- readRDS("all_models_by_period.rds")
#

# ─────────────────────────────────────────────────────────────────────────────
# 🧠 Asignar el coverage_data adecuado a cada modelo por periodo
#for (period_name in names(all_models_by_period)) {
 # period_data <- coverage_data %>% filter(year %in% periods[[period_name]])
  
  #for (model_name in names(all_models_by_period[[period_name]])) {
   # model <- all_models_by_period[[period_name]][[model_name]]
    
   # if (!is.null(model)) {
    #  model$call$data <- period_data
    #  all_models_by_period[[period_name]][[model_name]] <- model
    #}
  #}
#}

# ─────────────────────────────────────────────────────────────────────────────
# 🔁 Renombrar todos los modelos agregando sufijo de periodo
create_named_models_by_period <- function(all_models_by_period, period_suffixes = names(all_models_by_period)) {
  names(all_models_by_period) <- period_suffixes
  named_models <- list()
  
  for (i in seq_along(all_models_by_period)) {
    models <- all_models_by_period[[i]]
    suffix <- period_suffixes[i]
    renamed_models <- setNames(models, paste0(names(models), "_", suffix))
    named_models[[i]] <- renamed_models
  }
  
  all_named_models <- do.call(c, named_models)
  return(all_named_models)
}

all_named_models <- create_named_models_by_period(all_models_by_period)

# ─────────────────────────────────────────────────────────────────────────────
# 💾 Guardar las versiones parchadas
saveRDS(all_models_by_period, "all_models_by_period_with_data.rds")
saveRDS(all_named_models, "all_named_models_with_data.rds")

all_named_models <- readRDS("all_named_models_with_data.rds")

# 4. Función para extraer data de residuos por clase
extract_residual_data <- function(model, nameofoutcome, nameofage = "ano", data, model_label) {
  k <- ifelse(is.null(model$ng), 1, model$ng)
  preds <- model$pred
  names(preds)[6] <- "outcome_value_pred"
  nameofid <- names(model$pred)[1]
  
  model_data <- data %>%
  group_by(.data[[nameofid]]) %>%
  mutate(row_id = row_number()) %>%
  ungroup()

  
  preds <- preds %>%
    group_by(.data[[nameofid]]) %>%
    mutate(row_id = row_number()) %>%
    ungroup()
  
  test <- left_join(preds, model$pprob, by = nameofid) %>%
    left_join(select(model_data, all_of(nameofid), !!nameofoutcome, !!nameofage, row_id),
              by = c(nameofid, "row_id"))
  
  residual_df <- purrr::map_dfr(1:k, function(i) {
    class_col <- if (k == 1) "pred_ss1" else paste0("pred_ss", i)
    test %>%
      filter(k == 1 | class == i) %>%
      mutate(
        Residuals = !!parse_expr(nameofoutcome) - !!parse_expr(class_col),
        ano_real = .data[[nameofage]],
        class_label = paste("Class", i),
        model_label = model_label
      ) %>%
      select(ano_real, Residuals, class_label, model_label)
  })
  
  return(residual_df)
}

# 5. Definir modelos y outcomes a graficar
models_to_plot <- list(
  "DGCC 2011–2023" = all_named_models[["5class_linear_nre_homocedastic_dgcc_model_2011_2023"]],
  "DRSC 2011–2023" = all_named_models[["4class_linear_nre_homocedastic_drsc_model_2011_2023"]]
)
outcomes <- c("dgcc","drsc")
names(outcomes) <- names(models_to_plot)

# 6. Extraer todos los datos de residuos
residual_data_all <- purrr::pmap_dfr(
  list(models_to_plot, outcomes, names(models_to_plot)),
  ~ extract_residual_data(..1, ..2, nameofage = "ano", data = coverage_data, model_label = ..3)
)

# 7. Preparar niveles de factores
residual_data_all$class_label <- factor(residual_data_all$class_label, levels = paste("Class", 1:4))
residual_data_all$model_label <- factor(residual_data_all$model_label, 
                                        levels = c("DGCC 2011–2023","DRSC 2011–2023"))

# 8. Función para plotear cada modelo
plot_residual_block <- function(df, title) {
  ggplot(df, aes(x = ano_real, y = Residuals)) +
    geom_point(size = 0.2, alpha = 0.3) +
    stat_summary(fun = mean, geom = "line", color = "darkcyan", size = 0.6) +
    facet_wrap(~ class_label, ncol = 5) +
    ylim(-1, 1) +
    scale_x_continuous(breaks = seq(2011, 2023, 2)) +
    theme_bw(base_size = 9) +
    labs(x = "Year", y = "Residuals", title = title) +
    theme(
      strip.text = element_text(face = "bold", size = 8),
      axis.text.x = element_text(size = 7, angle = 45, hjust = 1),
      axis.text.y = element_text(size = 7),
      plot.title = element_text(face = "bold", size = 10, hjust = 0),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )
}

# 9. Crear los bloques de plots
plot_dgcc_2023 <- plot_residual_block(residual_data_all %>% filter(model_label == "DGCC 2011–2023"), "DGCC 2011–2023")
plot_drsc_2023 <- plot_residual_block(residual_data_all %>% filter(model_label == "DRSC 2011–2023"), "DRSC 2011–2023")

# 10. Combinar todos los gráficos con patchwork
final_residual_plot <- (
  plot_dgcc_2023 /
    plot_drsc_2023 
) +  
  plot_annotation(
    title = "Supplementary Figure S1. Standardised residual plots by latent class under Model A",
    subtitle = "Each panel shows the distribution of standardised residuals over time (Year) for a given latent class under a linear fixed-effects, homoscedastic model (Model A). The first row corresponds to DGCC (2011–2023), the second to DGCC (2011–2019), the third to DRSC (2011–2023), and the fourth to DRSC (2011–2019).",
    theme = theme(
      plot.title = element_text(size = 16, face = "bold"),
      plot.subtitle = element_text(size = 10)
    )
 
)
# 11. Mostrar
final_residual_plot



```

**Supplementary Figures S2–S5. *Latent class selection elbows plots across ten different structures in DGCC 2011-2023.***\
Each figure presents model comparison panels used to guide latent class number selection for a given outcome and time period. Within each panel, the black line displays the Bayesian Information Criterion (BIC) across models with 1 to 7 latent classes, allowing visual identification of the “elbow point” where model fit improvements begin to plateau. The vertical stacked bars represent the proportion of the population assigned to each class at each solution, with darker red hues indicating smaller class sizes. Together, the BIC curve and class distribution inform model selection by balancing statistical fit and classification adequacy. These plots support the decisions reported in Table 1 and discussed in the model adequacy assessment.

```{r}
#| message: false
#| warning: false
#| fig-height: 4
#| fig-width: 10
#| fig-cap: "Figure S2. Latent class selection plots for DGCC (2011–2023)"

# ───── Load libraries ─────
library(dplyr)
library(ggplot2)
library(tidyr)
library(stringr)
library(purrr)
library(gridExtra)
library(readr)



# ───── 1B. Automatically exclude models with abnormally high BICs ─────
model_adequacy_table <- readr::read_csv("model_adequacy_table.csv")



models_to_exclude <- model_adequacy_table %>%
  group_by(Model) %>%
  arrange(-BIC) %>% 
  filter(BIC > 1e6) %>% 
  pull(Model)
            


model_adequacy_table <- model_adequacy_table %>%
  filter(!Model %in% models_to_exclude)



filtered_df <- model_adequacy_table %>%
  filter(str_detect(Model, "2011_2023")) %>%
  mutate(
    Structure = Model %>%
      str_replace("^[0-9]+class_", "") %>%
      str_replace("_model_.*", ""),
    Period = str_extract(Model, "\\d{4}_\\d{4}"),
    Outcome = str_extract(Model, "_(drsc|dgcc)_") %>% str_replace_all("_", "")
  )

# ───── 2. Create Pretty Title Mapping (Model A | DGCC | 2011–2023) ─────
structure_labels <- filtered_df %>%
  mutate(
    Outcome = toupper(Outcome),
    Label = case_when(
      str_detect(Structure, "linear_nre_homocedastic") ~ "A",
      str_detect(Structure, "linear_nre_heterocedastic") ~ "B",
      str_detect(Structure, "quadratic_nre") ~ "C",
      str_detect(Structure, "cubic_nre") ~ "D",
      str_detect(Structure, "linear_random_intercept_slope") ~ "F",
      str_detect(Structure, "linear_random_intercept") ~ "E",
      str_detect(Structure, "quadratic_random_effects_prop") ~ "H",
      str_detect(Structure, "quadratic_random_effects") ~ "G",
      str_detect(Structure, "cubic_random_effects_prop") ~ "J",
      str_detect(Structure, "cubic_random_effects") ~ "I",
      TRUE ~ "Other"
    ),
    Period_pretty = str_replace(Period, "_", "–"),
    PrettyTitle = paste("Model", Label, "|", Outcome, "|", Period_pretty)
  ) %>%
  distinct(Structure, Period, PrettyTitle)

# ───── 3. Prepare long-format class proportions ─────
proportion_cols <- names(filtered_df)[str_detect(names(filtered_df), "^%class")]

class_df_long <- filtered_df %>%
  pivot_longer(cols = all_of(proportion_cols),
               names_to = "Class",
               values_to = "Proportion") %>%
  mutate(Class = factor(Class, levels = proportion_cols))

# ───── 4. Filter combinations with at least 2 G values ─────
valid_keys <- class_df_long %>%
  distinct(Structure, Period, G) %>%
  group_by(Structure, Period) %>%
  dplyr::summarise(n_G = n(), .groups = "drop") %>%
  filter(n_G >= 2) %>%
  select(Structure, Period)

# Add pretty titles to the valid ones
plot_keys <- valid_keys %>%
  left_join(structure_labels, by = c("Structure", "Period"))

# ───── 5. Define plotting function with custom title ─────
plot_elbow_stack <- function(df_model, title = NULL) {
  structure <- unique(df_model$Structure)
  period <- unique(df_model$Period)
  
  df_summary <- df_model %>%
    group_by(G, Class) %>%
    dplyr::summarise(Proportion = mean(Proportion, na.rm = TRUE), .groups = "drop")
  
  bic_df <- df_model %>%
    group_by(G) %>%
    dplyr::summarise(BIC = mean(BIC, na.rm = TRUE), .groups = "drop")
  
  if (nrow(bic_df) < 2) {
    message("Skipping plot for ", structure, " | ", period, ": not enough BIC values")
    return(NULL)
  }
  
  bic_range <- range(bic_df$BIC, na.rm = TRUE)
  bic_min <- bic_range[1]
  bic_max <- bic_range[2]
  scale_factor <- 100 / (bic_max - bic_min)
  
  bic_df <- bic_df %>%
    mutate(BIC_scaled = (BIC - bic_min) * scale_factor)
  
  ggplot(df_summary, aes(x = factor(G), y = Proportion, fill = Class)) +
    geom_bar(stat = "identity", color = "white") +
    scale_fill_brewer(palette = "Reds") +
    geom_line(data = bic_df, aes(x = factor(G), y = BIC_scaled, group = 1),
              inherit.aes = FALSE, color = "black", size = 1) +
    geom_point(data = bic_df, aes(x = factor(G), y = BIC_scaled),
               inherit.aes = FALSE, color = "black", size = 2) +
    scale_y_continuous(
      name = "% Proportion of Population",
      sec.axis = sec_axis(~ . / scale_factor + bic_min, name = "BIC")
    ) +
    labs(
      title = title,
      x = "Number of Classes",
      fill = "Class"
    ) +
    theme_minimal() +
    theme(legend.position = "none")
}

# ───── 6. Generate plots with titles ─────
plot_data_list <- purrr::map2(
  .x = plot_keys$Structure,
  .y = plot_keys$Period,
  .f = ~ class_df_long %>% filter(Structure == .x, Period == .y)
)

plots <- purrr::map2(
  .x = plot_data_list,
  .y = plot_keys$PrettyTitle,
  .f = plot_elbow_stack
)

# Remove NULL plots
valid_idx <- purrr::map_lgl(plots, ~ !is.null(.))
plots <- plots[valid_idx]
names(plots) <- plot_keys$PrettyTitle[valid_idx]

# ───── 7. Helper: Reorder plots by Model A–J ─────
extract_label <- function(name) {
  str_extract(name, "Model [A-J]") %>% str_remove("Model ")
}

order_plot_group_by_label <- function(plot_list) {
  df_order <- tibble(name = names(plot_list)) %>%
    mutate(label = extract_label(name)) %>%
    mutate(order = match(label, LETTERS[1:10])) %>%
    arrange(order)
  plot_list[df_order$name]
}

# ───── 8. Helper function to plot any group (by outcome & period) ─────
plot_group_grid <- function(plots, outcome, period) {
  # Normalize inputs to match title format
  outcome <- toupper(outcome)
  period_pretty <- str_replace(period, "_", "–")
  
  group <- plots[str_detect(names(plots), outcome) &
                   str_detect(names(plots), period_pretty)]
  
  if (length(group) == 0) {
    message("❌ No plots found for ", outcome, " | ", period_pretty)
  } else {
    ordered_group <- order_plot_group_by_label(group)
    
    grid.arrange(
      grobs = ordered_group,
      ncol = 5,
      nrow = 2,
      top = paste0(outcome, " ", period_pretty, " — Models A to J")
    )
  }
}

# ───── 9. Call the function for all desired groups ─────

plot_group_grid(plots, outcome = "dgcc", period = "2011_2023") 




```

```{r}
#| message: false
#| warning: false
#| fig-height: 4
#| fig-width: 10
#| fig-cap: "Figure S2. Latent class selection plots for DRSC (2011–2023)"

plot_group_grid(plots, outcome = "drsc", period = "2011_2023") 

```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false

selected_structures <- c(
  "class_cubic_nre_dgcc_model_2011_2023",
  "class_quadratic_nre_dgcc_model_2011_2019",
  "class_cubic_nre_drsc_model_2011_2023",
  "class_quadratic_random_effects_prop_drsc_model_2011_2019"
)

model_adequacy_table %>%
  filter(str_detect(Model, paste(selected_structures, collapse = "|"))) %>% 
  filter(str_detect(Model, "2011_2023") | str_detect(Model, "2011_2019")) %>%
  mutate(
    Period = case_when(
      str_detect(Model, "2011_2023") ~ "2011–2023",
      str_detect(Model, "2011_2019") ~ "2011–2019",
      TRUE ~ NA_character_
    ),
    Structure = case_when(
      str_detect(Model, "linear_nre_homocedastic") ~ "A",
      str_detect(Model, "linear_nre_heterocedastic") ~ "B",
      str_detect(Model, "quadratic_nre") ~ "C",
      str_detect(Model, "cubic_nre") ~ "D",
      str_detect(Model, "linear_random_intercept_slope") ~ "E",
      str_detect(Model, "linear_random_intercept") ~ "F",
      str_detect(Model, "quadratic_random_effects_prop") ~ "G",
      str_detect(Model, "quadratic_random_effects") ~ "H",
      str_detect(Model, "cubic_random_effects_prop") ~ "I",
      str_detect(Model, "cubic_random_effects") ~ "J",
      TRUE ~ "Unknown"
    ),
    Outcome = case_when(
      str_detect(Model, "dgcc") ~ "DGCC",
      str_detect(Model, "drsc") ~ "DRSC",
      TRUE ~ "Other"
    ),
    non_converged = abs(BIC) > 1e6,  # flag large BIC
    BIC_display = ifelse(non_converged, "*", scales::number(BIC, accuracy = 0.1, big.mark = ","))
  ) %>%
  mutate(
    entropy = round(entropy, 2),
    Lowest_APPA = round(Lowest_APPA * 100, 2),
    Lowest_OCC = round(Lowest_OCC, 1),
    Smallest_Class_Size_Percentage = round(Smallest_Class_Size_Percentage, 1),
    DoS_Mahalanobis = round(DoS_Mahalanobis, 1)
  ) %>%
  select(Outcome, Period, Model, Structure, G, BIC_display, entropy,
         Smallest_Class_Size_Percentage, Lowest_APPA,
         Lowest_OCC, Highest_Mismatch, DoS_Mahalanobis) %>%
  dplyr::rename(
    "Nº of classes" = G,
    "BIC" = BIC_display,
    "Relative entropy" = entropy,
    "Smallest class size (%)" = Smallest_Class_Size_Percentage,
    "Lowest APPA (%)" = Lowest_APPA,
    "Lowest OCC" = Lowest_OCC,
    "Highest MMV" = Highest_Mismatch,
    "Mahalanobis distance" = DoS_Mahalanobis
  ) %>%
  arrange(Outcome, desc(Period), Structure) %>% 
  select(-Outcome, -Period, -Model) %>%
  #filter(Structure %in% c("D", "C", "G")) %>% 
  gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  ) %>% 
  tab_style(
   style = cell_text(weight = "bold"),
   locations = cells_body(rows = c(5, 11, 18, 25))
  ) %>% 
  tab_row_group(
    group = "Diabetic retinopathy screening coverage 2011-2019",
    rows = 22:28
  ) %>% 
  tab_row_group(
    group = "Diabetic retinopathy screening coverage 2011-2023",
    rows =15:21
  ) %>% 
  tab_row_group(
    group = "Diabetic glycemic control coverage 2011-2019",
    rows = 8:14
  ) %>% 
  tab_row_group(
    group = "Diabetic glycemic control coverage 2011-2023",
    rows =1:7
  ) %>% 
  tab_source_note(source_note = md("**Abbreviations:** LCMM - Latent class mixture model; BIC - Bayesian information criterion; SCS - Smallest class size; APPA - Average posterior probability; MMV - Mismatch value; OCC - Odds of correct classification. * Model did not converge; BIC not reliable.")) %>% 
  tab_header(
    title = md("**Supplementary Table S3. Number of classes (K=1–7) using quadratic and cubic non random effects and quadratic radnom effects proportional structure Model F (proportional covariance structure) by gender**"))


```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false


model_adequacy_table <- read.csv("model_adequacy_table.csv")

selected_models <- c(
  "5class_cubic_nre_dgcc_model_2011_2023",
  "4class_quadratic_nre_dgcc_model_2011_2019",
  "4class_cubic_nre_drsc_model_2011_2023",
  "4class_quadratic_random_effects_prop_drsc_model_2011_2019"
)


 model_adequacy_table %>%
  filter(
    (str_detect(Model, "^5class_") & str_detect(Model, "dgcc_model_2011_2023")) |  # <- switch here
    (str_detect(Model, "^4class_") & str_detect(Model, "dgcc_model_2011_2019")) |
    (str_detect(Model, "^4class_") & str_detect(Model, "drsc_model_2011_2023")) |
    (str_detect(Model, "^4class_") & str_detect(Model, "drsc_model_2011_2019"))
  ) %>%
  mutate(
    Period = case_when(
      str_detect(Model, "2011_2023") ~ "2011–2023",
      str_detect(Model, "2011_2019") ~ "2011–2019",
      TRUE ~ NA_character_
    ),
    Structure = case_when(
      str_detect(Model, "linear_nre_homocedastic") ~ "A",
      str_detect(Model, "linear_nre_heterocedastic") ~ "B",
      str_detect(Model, "quadratic_nre") ~ "C",
      str_detect(Model, "cubic_nre") ~ "D",
      str_detect(Model, "linear_random_intercept_slope") ~ "E",
      str_detect(Model, "linear_random_intercept") ~ "F",
      str_detect(Model, "quadratic_random_effects_prop") ~ "G",
      str_detect(Model, "quadratic_random_effects") ~ "H",
      str_detect(Model, "cubic_random_effects_prop") ~ "I",
      str_detect(Model, "cubic_random_effects") ~ "J",
      TRUE ~ "Unknown"
    ),
    Outcome = case_when(
      str_detect(Model, "dgcc") ~ "DGCC",
      str_detect(Model, "drsc") ~ "DRSC",
      TRUE ~ "Other"
    ),
    non_converged = abs(BIC) > 1e6,  # flag large BIC
    BIC_display = ifelse(non_converged, "*", scales::number(BIC, accuracy = 0.1, big.mark = ","))
  ) %>%
  mutate(
    entropy = round(entropy, 2),
    Lowest_APPA = round(Lowest_APPA * 100, 2),
    Lowest_OCC = round(Lowest_OCC, 1),
    Smallest_Class_Size_Percentage = round(Smallest_Class_Size_Percentage, 1),
    DoS_Mahalanobis = round(DoS_Mahalanobis, 1)
  ) %>%
  select(Outcome, Period, Model, Structure, G, BIC_display, entropy,
         Smallest_Class_Size_Percentage, Lowest_APPA,
         Lowest_OCC, Highest_Mismatch, DoS_Mahalanobis) %>%
  dplyr::rename(
    "Nº of classes" = G,
    "BIC" = BIC_display,
    "Relative entropy" = entropy,
    "Smallest class size (%)" = Smallest_Class_Size_Percentage,
    "Lowest APPA (%)" = Lowest_APPA,
    "Lowest OCC" = Lowest_OCC,
    "Highest MMV" = Highest_Mismatch,
    "Mahalanobis distance" = DoS_Mahalanobis
  ) %>%
  arrange(Outcome, desc(Period), Structure) %>%
  select(-Outcome, -Period, -Model) %>%
  gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  )  %>% 
   tab_style(
    style = cell_text(weight = "bold"),
    locations = cells_body(rows = c(4, 13, 24, 37))
  ) %>% 
  tab_row_group(
    group = "Diabetic retinopathy screening coverage 2011-2019",
    rows = 31:40
  ) %>% 
  tab_row_group(
    group = "Diabetic retinopathy screening coverage 2011-2023",
    rows =21:30
  ) %>% 
  tab_row_group(
    group = "Diabetic glycemic control coverage 2011-2019",
    rows = 11:20
  ) %>% 
  tab_row_group(
    group = "Diabetic glycemic control coverage 2011-2023",
    rows =1:10
  ) %>% 
  tab_source_note(source_note = md("**Abbreviations:** LCMM - Latent class mixture model; BIC - Bayesian information criterion; SCS - Smallest class size; APPA - Average posterior probability; MMV - Mismatch value; OCC - Odds of correct classification. * Model did not converge; BIC not reliable.")) %>% 
  tab_header(
    title = md("**Supplementary Table S4. Description of the 10 candidate model structures tested in the LCMM analysis**"))

```

```{r}
#| label: individual-trajectories-plot
#| echo: false
#| message: false
#| warning: false
#| fig-width: 10
#| fig-height: 7
#| fig-cap: "Figure S6. Latent class selection plots for DRSC (2011–2023)"


# 📂 Cargar el archivo de modelos
all_named_models <- readRDS("all_named_models.rds")

# 📋 Definir cuáles modelos quieres graficar
model_names_to_plot <- c(
  "5class_cubic_nre_dgcc_model_2011_2023",
  #"4class_quadratic_nre_dgcc_model_2011_2019",
  "4class_cubic_nre_drsc_model_2011_2023"#,
 # "4class_quadratic_random_effects_prop_drsc_model_2011_2019"
)

# 🏷️ Etiquetas de las trayectorias
trajectory_labels <- list(
  `5class_cubic_nre_dgcc_model_2011_2023` = c(
    "Consistently lower", "Stable medium", "Stable upper medium", "Deteriorating", "Highest"
  ),
 # `4class_quadratic_nre_dgcc_model_2011_2019` = c(
 #   "Consistently lower", "Stable medium", "Stable upper medium", "Highest"
 # ),
  `4class_cubic_nre_drsc_model_2011_2023` = c(
    "Consistently low", "Stable medium", "Increasing", "Highest decreasing"
  )#,
  #`4class_quadratic_random_effects_prop_drsc_model_2011_2019` = c(
  #  "Consistently low", "Stable medium", "Recovering", "Highest"
  #)
)

# 🏷️ Títulos de los modelos
model_titles <- c(
  "5class_cubic_nre_dgcc_model_2011_2023" = "Five-class model for glycaemic control (2011–2023)",
  #"4class_quadratic_nre_dgcc_model_2011_2019" = "Four-class model for glycaemic control (2011–2019)",
  "4class_cubic_nre_drsc_model_2011_2023" = "Four-class model for DR screening (2011–2023)"#,
  #"4class_quadratic_random_effects_prop_drsc_model_2011_2019" = "Four-class model for DR screening (2011–2019)"
)

# ⚙️ Crear los gráficos
individual_trajectories_plots <- purrr::map(model_names_to_plot, function(model_name) {
  
  model <- all_named_models[[model_name]]
  
  # ✅ Verificación de componentes
  if (is.null(model) || is.null(model$call$data) || is.null(model$pred) || is.null(model$pprob)) {
    cat(paste0("⚠️ Skipping model: ", model_name, "\n"))
    return(NULL)
  }
  
  # 🔍 Outcome variable
  outcome_var <- ifelse(str_detect(model_name, "dgcc"), "dgcc", "drsc")
  
  # 🛠️ Preprocesar datos
  model_data <- model$call$data %>%
    arrange(id, year) %>%
    group_by(id) %>%
    mutate(row_id = row_number()) %>%
    ungroup()
  
  pred_data <- model$pred
  
  # 🔥 Verificar si pred_data tiene columna "time"
  if ("time" %in% names(pred_data)) {
    pred_data <- pred_data %>%
      arrange(id, time)
  } else {
    pred_data <- pred_data %>%
      arrange(id)
  }
  
  pred_data <- pred_data %>%
    group_by(id) %>%
    mutate(row_id = row_number()) %>%
    ungroup()
  
  merged_df <- left_join(model_data, pred_data, by = c("id", "row_id")) %>%
    left_join(model$pprob, by = "id") %>%
    filter(!is.na(class))
  
  # 🧹 Ordenar las clases
  class_order <- merged_df %>%
    group_by(class) %>%
    dplyr::summarise(mean_val = mean(.data[[outcome_var]], na.rm = TRUE), .groups = "drop") %>%
    arrange(mean_val) %>%
    mutate(class_order = row_number())
  
  merged_df <- merged_df %>%
    left_join(class_order, by = "class") %>%
    mutate(class = class_order)
  
  label_df <- merged_df %>%
    distinct(id, class) %>%
    group_by(class) %>%
    dplyr::summarise(n = n(), .groups = "drop") %>%
    mutate(
      percentage = n / sum(n),
      label = paste0(trajectory_labels[[model_name]], " (", percent(percentage, accuracy = 0.1), ")")
    ) %>%
    arrange(class)
  
  merged_df <- merged_df %>%
    left_join(label_df, by = "class") %>%
    mutate(label = factor(label, levels = label_df$label))
  
  # 🎨 Construir el gráfico
  ggplot(merged_df, aes(x = year, y = .data[[outcome_var]], group = id, color = label)) +
    geom_line(alpha = 0.15, linewidth = 0.3) +
    stat_summary(fun = mean, geom = "line", aes(group = label), linewidth = 0.9) +
    facet_wrap(~ label, nrow = 1, strip.position = "top") +
    scale_color_lancet() +
    scale_y_continuous(limits = c(0, 1), labels = percent) +
    scale_x_continuous(breaks = seq(1, 13, by = 2), labels = seq(2011, 2023, by = 2)) +
    labs(
      title = model_titles[[model_name]],
      x = "Year",
      y = ifelse(outcome_var == "dgcc", 
                 "Diabetic glycaemic control coverage", 
                 "Diabetic retinopathy screening coverage")
    ) +
    theme_minimal(base_size = 10) +
    theme(
      strip.text = element_text(size = 8, face = "bold"),
      plot.title = element_text(size = 10, face = "bold", hjust = 0),
      axis.text = element_text(size = 7),
      axis.title = element_text(size = 8.5),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(),
      legend.position = "none"
    )
})

# 🧩 Combinar plots válidos
wrap_plots(purrr::compact(individual_trajectories_plots), ncol = 1) +
  plot_annotation(
    title = "Raw individual trajectories by latent class (ordered within model)",
    subtitle = "Each facet uses model-specific class ordering and consistent color palette",
    theme = theme(
      plot.title = element_text(size = 13, face = "bold", hjust = 0),
      plot.subtitle = element_text(size = 10, hjust = 0)
    )
  )
```

```{r}
#| echo: false
#| message: false
#| warning: false
#| fig-height: 9
#| fig-width: 10
#| paged-print: false
#| fig-align: center

# 📂 Load data
coverage_data <- read.csv("coverage_2011_2023_noq1.csv") %>%
  arrange(comuna2, ano) %>%
  mutate(
    year = ano - min(ano),
    id = comuna2,
    drsc = drs_coverage,
    dgcc = dm_coverage
  )

all_named_models <- readRDS("all_named_models.rds")

trajectory_labels <- list(
  `5class_cubic_nre_dgcc_model_2011_2023` = c("Consistently lower", "Stable medium", "Stable upper medium", "Deteriorating", "Highest"),
  `4class_quadratic_nre_dgcc_model_2011_2019` = c("Consistently lower", "Stable medium", "Stable upper medium", "Highest"),
  `4class_cubic_nre_drsc_model_2011_2023` = c("Consistently low", "Stable medium", "Increasing", "Highest decreasing"),
  `4class_quadratic_random_effects_prop_drsc_model_2011_2019` = c("Consistently low", "Stable medium", "Recovering", "Highest")
)

model_names_to_plot <- c(
  "5class_cubic_nre_dgcc_model_2011_2023",
  "4class_quadratic_nre_dgcc_model_2011_2019",
  "4class_cubic_nre_drsc_model_2011_2023",
  "4class_quadratic_random_effects_prop_drsc_model_2011_2019"
)

selected_models <- all_named_models[model_names_to_plot]
residual_plot_list <- list()

# 📈 Loop for models
for (i in seq_along(selected_models)) {
  
  model_name <- names(selected_models)[i]
  model <- selected_models[[i]]
  
  outcome_var <- ifelse(grepl("drsc", model_name, ignore.case = TRUE), "drsc", "dgcc")
  
  model_data <- model$call$data %>%
    group_by(id) %>%
    mutate(row_id = row_number()) %>%
    ungroup()
  
  pred_df <- model$pred %>%
    group_by(id) %>%
    mutate(row_id = row_number()) %>%
    ungroup()
  
  merged_df <- left_join(model_data, pred_df, by = c("id", "row_id")) %>%
    left_join(model$pprob, by = "id") %>%
    filter(!is.na(class)) %>%
    rowwise() %>%
    mutate(
      pred = get(paste0("pred_m", class)),
      prob = get(paste0("prob", class)),
      residual = .data[[outcome_var]] - pred
    ) %>%
    ungroup()
  
  summary_residuals <- merged_df %>%
    group_by(year, class) %>%
    dplyr::summarise(
      mean_obs = wtd.mean(obs, weights = prob, na.rm = TRUE),
      sd_resid = sqrt(wtd.var(residual, weights = prob, na.rm = TRUE)),
      lower = mean_obs - sd_resid,
      upper = mean_obs + sd_resid,
      .groups = "drop"
    ) %>%
    mutate(model = model_name)
  
  # Reorder classes based on average mean
  class_order <- summary_residuals %>%
    group_by(class) %>%
    dplyr::summarise(avg_mean_obs = mean(mean_obs, na.rm = TRUE)) %>%
    arrange(avg_mean_obs) %>%
    mutate(order_class = row_number())
  
  # Assign labels based on order_class
  class_percentages <- merged_df %>%
    distinct(id, class) %>%
    left_join(class_order, by = "class") %>%
    group_by(order_class) %>%
    dplyr::summarise(n = n(), .groups = "drop") %>%
    mutate(percentage = n / sum(n)) %>%
    arrange(order_class)
  
  trajectory_vector <- trajectory_labels[[model_name]]
  
  if (length(trajectory_vector) != nrow(class_percentages)) {
    stop("⚠️ Número de etiquetas no coincide con el número de clases")
  }
  
  class_percentages <- class_percentages %>%
    mutate(label = paste0(trajectory_vector, " (", percent(percentage, accuracy = 0.1), ")"))
  
  # Final dataset for plotting
  summary_residuals_plot <- summary_residuals %>%
    left_join(class_order, by = "class") %>%
    left_join(class_percentages %>% select(order_class, label), by = "order_class") %>%
    mutate(label = factor(label, levels = class_percentages$label))
  
  # Y-axis label
  y_axis_label <- if (grepl("dgcc", model_name, ignore.case = TRUE)) {
    "Proportion of T2DM individuals with HbA1C < 7%"
  } else {
    "Proportion of T2DM individuals with annual DR screening"
  }
  
  # 📈 Build plot
  plot_residual <- ggplot(summary_residuals_plot, aes(x = year, group = label)) +
    geom_line(aes(y = mean_obs, color = label), linewidth = 0.8) +
    geom_ribbon(aes(ymin = lower, ymax = upper, fill = label), alpha = 0.2) +
    scale_x_continuous(breaks = seq(1, 13, by = 2), labels = seq(2011, 2023, by = 2)) +
    scale_y_continuous(limits = c(0, 1), labels = percent) +
    scale_color_lancet(
      na.translate = FALSE,
      guide = guide_legend(override.aes = list(linetype = "solid", shape = NA))
    ) +
    scale_fill_lancet(guide = "none") +
    labs(
      x = "Year",
      y = y_axis_label,
      color = "Latent class"
    ) +
    theme_bw() +
    guides(color = guide_legend(nrow = 2, byrow = TRUE, title.position = "top", title.hjust = 0)) +
    theme(
      legend.position = c(0.02, 0.98),
      legend.justification = c(0, 1),
      legend.direction = "horizontal",
      legend.box = "horizontal",
      legend.margin = margin(t = 1, b = 1, r = 1, l = 1),
      legend.key.size = unit(0.2, "cm"),
      legend.background = element_rect(fill = "transparent", color = NA),
      legend.text = element_text(size = 7),
      legend.title = element_text(size = 8, face = "bold"),
      axis.text = element_text(size = 6.5),
      axis.title = element_text(size = 7.5),
      panel.grid.major = element_blank(),
      panel.grid.minor = element_blank()
    )
  
  residual_plot_list[[i]] <- plot_residual
}

# 🖼 Titles
dgcc_title <- patchwork::wrap_elements(grid::textGrob(
  "Diabetic glycaemic control coverage residual Elsensohn envelopes plots", 
  x = 0, hjust = 0, gp = grid::gpar(fontface = "bold", fontsize = 13)
))

drsc_title <- patchwork::wrap_elements(grid::textGrob(
  "Diabetic retinopathy screening coverage residual Elsensohn envelopes plots", 
  x = 0, hjust = 0, gp = grid::gpar(fontface = "bold", fontsize = 13)
))

# 🧩 Final combination
combined_plot <- (
  dgcc_title / (residual_plot_list[[1]] | residual_plot_list[[2]]) /
    drsc_title / (residual_plot_list[[3]] | residual_plot_list[[4]])
) +
  patchwork::plot_layout(heights = c(0.1, 1, 0.1, 1))

combined_plot



```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false


library(dplyr)
library(tidyr)
library(tibble)
library(stringr)

# Capturar salida del summary
summary_lines <- capture.output(summary(all_named_models[["5class_cubic_nre_dgcc_model_2011_2023"]]))

# Extraer líneas relevantes
start <- which(grepl("^Fixed effects in the longitudinal model:", summary_lines)) + 2
end <- which(grepl("^\\s*Residual standard error", summary_lines)) - 1
long_lines <- summary_lines[start:end]

# Filtrar líneas vacías
long_lines <- long_lines[nzchar(long_lines)]

# Parseo robusto con regex
long_df <- long_lines %>%
  str_trim() %>%
  str_match("^(.+?)\\s+(class\\d)\\s+([-0-9.Ee]+)\\s+([-0-9.Ee]+)\\s+([-0-9.Ee]+)\\s+([-0-9.Ee]+)") %>%
  as.data.frame() %>%
  filter(!is.na(V2)) %>%
  select(term = V2, class = V3, coef = V4, se = V5, wald = V6, pvalue = V7) %>%
  mutate(across(c(coef, se, wald, pvalue), ~ suppressWarnings(as.numeric(.)))) %>%
  mutate(
    coef = round(coef, 5),
    se = round(se, 5),
    wald = round(wald, 3),
    pvalue = round(pvalue, 3)
  ) %>%
  relocate(class, term)

# Mostrar tabla
long_df 






```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false

model_names <- c(
  "5class_cubic_nre_dgcc_model_2011_2023",
  "4class_quadratic_nre_dgcc_model_2011_2019",
  "4class_cubic_nre_drsc_model_2011_2023",
  "4class_quadratic_random_effects_prop_drsc_model_2011_2019"
)

make_fur_table <- function(model_name, all_named_models, label_vector = NULL) {
  model <- all_named_models[[model_name]]
  
  # Capturar líneas relevantes del resumen
  summary_lines <- capture.output(summary(model))
  start <- which(grepl("^Fixed effects in the longitudinal model:", summary_lines)) + 2
  end <- which(grepl("^\\s*Residual standard error", summary_lines)) - 1
  long_lines <- summary_lines[start:end] %>%
    stringr::str_trim() %>%
    .[. != ""]
  
  if (length(long_lines) > 0 && grepl("class", long_lines[1])) {
    long_lines <- long_lines[-1]
  }
  
  # Extraer tabla de coeficientes
  pattern <- "^\\s*(\\w+|I\\(year\\^\\d\\))\\s+(class\\d)\\s+([-0-9.Ee]+)\\s+([-0-9.Ee]+)\\s+([-0-9.Ee]+)\\s+([0-9.Ee]+)"
  long_df <- stringr::str_match(long_lines, pattern) %>%
    as.data.frame() %>%
    dplyr::select(term = V2, class = V3, coef = V4, se = V5, wald = V6, pvalue = V7) %>%
    dplyr::mutate(
      dplyr::across(c(coef, se, wald, pvalue), as.numeric),
      coef_2010 = coef
    )
  
  # Detectar términos disponibles para calcular coef_2011
  terms_present <- unique(long_df$term)
  terms_to_use <- intersect(c("intercept", "year", "I(year^2)", "I(year^3)"), terms_present)
  
  coef_2011_df <- long_df %>%
    dplyr::filter(term %in% terms_to_use) %>%
    tidyr::pivot_wider(id_cols = class, names_from = term, values_from = coef_2010, values_fill = 0) %>%
    dplyr::mutate(
      coef_2011 = rowSums(dplyr::across(dplyr::all_of(terms_to_use)))
    ) %>%
    dplyr::select(class, coef_2011)
  
  final_df <- long_df %>%
    dplyr::left_join(coef_2011_df, by = "class") %>%
    dplyr::mutate(
      coef_2011 = ifelse(term == "intercept", coef_2011, coef_2010),
      class_num = as.integer(stringr::str_extract(class, "\\d+"))
    )
  
  # Obtener orden de clases observado
  observed_df <- dplyr::left_join(model$pred, model$pprob, by = "id") %>%
    dplyr::mutate(
      class_num = as.integer(as.character(class)),
      obs = as.numeric(obs)
    )
  
  class_order <- observed_df %>%
    dplyr::group_by(class_num) %>%
    dplyr::summarise(avg_observed = mean(obs, na.rm = TRUE), .groups = "drop") %>%
    dplyr::arrange(avg_observed) %>%
    dplyr::mutate(label = if (is.null(label_vector)) paste("Class", dplyr::row_number()) else label_vector)
  
  final_df <- final_df %>%
    dplyr::left_join(class_order, by = "class_num") %>%
    dplyr::mutate(new_class = as.integer(dplyr::dense_rank(avg_observed))) %>%
    dplyr::arrange(new_class, term)
  
  term_order <- c("intercept", "year", "I(year^2)", "I(year^3)")
  final_df <- final_df %>%
    dplyr::mutate(term = factor(term, levels = term_order, ordered = TRUE)) %>%
    dplyr::arrange(new_class, term)
  
  row_indices <- split(1:nrow(final_df), final_df$new_class)
  
  gt_table <- final_df %>%
  dplyr::filter(!is.na(term)) %>%
  dplyr::select(term, coef_2011, se, pvalue) %>%
  dplyr::mutate(
    coef_2011 = formatC(coef_2011, format = "f", digits = 2),
    se        = formatC(se,        format = "f", digits = 2),
    pvalue    = formatC(pvalue,    format = "f", digits = 3)
  ) %>%
  gt::gt() %>%
    gt::tab_options(
      table.font.size = 10,
      data_row.padding = gt::px(0),
      table.border.top.color = "black",
      heading.border.bottom.color = "black",
      row_group.border.top.color = "black",
      row_group.border.bottom.color = "white",
      table.border.bottom.color = "white",
      column_labels.border.top.color = "black",
      column_labels.border.bottom.color = "black",
      table_body.border.bottom.color = "black",
      table_body.hlines.color = "white"
    ) %>%
    gt::tab_header(
      title = gt::md(paste0("**Estimates from  – ", model_name, "**"))
    )
  
  for (i in rev(sort(unique(final_df$new_class)))) {
    group_rows <- row_indices[[as.character(i)]]
    label_text <- paste("Class", i, "-", class_order$label[i])
    gt_table <- gt_table %>%
      gt::tab_row_group(
        label = label_text,
        rows = group_rows
      )
  }
  
  return(gt_table)
}

gt_tables <- purrr::map(model_names, ~ make_fur_table(.x, all_named_models))
gt_tables[[1]] 
gt_tables[[2]]
gt_tables[[3]]
gt_tables[[4]]


```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false


# 📂 1. Cargar datos
coverage_data <- read_csv("coverage_2011_2023_noq1.csv")
all_named_models <- readRDS("all_named_models.rds")
demographics <- read_csv("demographics.csv") %>%
   mutate(
    deprivation_index = index_standardized,
    urbanisation_classification = factor(urbanisation_classification, levels = c("Urbana", "Mixta", "Rural")),
    zona = factor(zona, levels = c("centro", "norte", "sur"))
  ) %>% 
  select(comuna, deprivation_index, urbanisation_classification, zona) %>% 
  drop_na() 
# ─────────────────────────────────────────────────────────────────────
# 🗂️ 2. Preprocesar datos
coverage_data <- coverage_data %>%
  arrange(comuna2, ano) %>%
  mutate(
    year = ano - min(ano),
    id = comuna2,
    drsc = drs_coverage,
    dgcc = dm_coverage
  )

# Definir periodos
periods <- list(
  "2011_2023" = 1:13,
  "2011_2019" = 1:9
)

# Asignar coverage_data a modelos
for (model_name in names(all_named_models)) {
  period_name <- ifelse(grepl("2011_2023", model_name), "2011_2023", "2011_2019")
  all_named_models[[model_name]]$call$data <- coverage_data %>% filter(year %in% periods[[period_name]])
}

# ─────────────────────────────────────────────────────────────────────
# 📋 3. Preparar merged_df de cada modelo
all_merged_df <- list()

for (model_name in names(all_named_models)) {
  model <- all_named_models[[model_name]]
  
  if (!is.null(model$call$data) && !is.null(model$pred) && !is.null(model$pprob)) {
    model_data <- model$call$data %>%
      group_by(id) %>%
      mutate(row_id = row_number()) %>%
      ungroup()
    
    pred_df <- model$pred %>%
      group_by(id) %>%
      mutate(row_id = row_number()) %>%
      ungroup()
    
    merged_df <- left_join(model_data, pred_df, by = c("id", "row_id")) %>%
      left_join(model$pprob, by = "id") %>%
      filter(!is.na(class))
    
    outcome_var <- ifelse(grepl("drsc", model_name), "drsc", "dgcc")
    
    class_order <- merged_df %>%
      group_by(class) %>%
      dplyr::summarise(mean_value = mean(.data[[outcome_var]], na.rm = TRUE), .groups = "drop") %>%
      arrange(mean_value) %>%
      mutate(class_order = row_number())
    
    merged_df <- merged_df %>%
      left_join(class_order, by = "class") %>%
      mutate(class = class_order) %>%
      select(-class_order)
    
    all_merged_df[[model_name]] <- merged_df
  }
}

# ─────────────────────────────────────────────────────────────────────
# 🧮 4. Regresiones multinomiales
id_to_comuna <- demographics %>%
  mutate(id = row_number()) %>%
  select(id, comuna)

regression_results <- list()

for (model_name in names(all_merged_df)) {
  
  df <- all_merged_df[[model_name]] %>%
    distinct(id, class) %>%
    left_join(id_to_comuna, by = "id") %>%
    left_join(demographics, by = "comuna")
  
  df$class <- as.factor(df$class)
  
  df$class <- relevel(df$class, ref = as.character(max(as.numeric(as.character(df$class)))))
  
  if (n_distinct(df$class) < 2) {
    cat("⚠️ Model skipped (only one class):", model_name, "\n")
    next
  }
  
model_multinom <- suppressWarnings(
  suppressMessages(
    {
      tmp <- capture.output(
        model <- nnet::multinom(class ~ deprivation_index + urbanisation_classification + zona, data = df)
      )
      model
    }
  )
)

  tidy_model <- broom::tidy(model_multinom, exponentiate = TRUE, conf.int = TRUE)
  
  tidy_model$model_name <- model_name
  
  regression_results[[model_name]] <- tidy_model
}

# 5. Limpiar nombres (ya lo tienes)
final_regression_table <- bind_rows(regression_results)

# 🔵 FALTA: Crear columna RRR_CI antes de pivot_wider
final_regression_table <- final_regression_table %>%
  mutate(
    RRR_CI = paste0(
      round(estimate, 2), 
      " [", round(conf.low, 2), ", ", round(conf.high, 2), "]"
    )
  )

# 🔵 Ahora sigue normal:



# ─────────────────────────────────────────────────────────────────────
# ✨ 5. Limpieza de nombres
clean_term_labels <- function(df) {
  df %>%
    mutate(term = case_when(
      term == "deprivation_index" ~ "Deprivation Index (continuous)",
      term == "urbanisation_classificationMixta" ~ "Mixta (Ref: Urbana)",
      term == "urbanisation_classificationRural" ~ "Rural (Ref: Urbana)",
      term == "zonanorte" ~ "Norte (Ref: Centro)",
      term == "zonasur" ~ "Sur (Ref: Centro)",
      term == "(Intercept)" ~ "(Intercept)",
      TRUE ~ term
    ))
}

final_regression_table <- clean_term_labels(final_regression_table)
# ─────────────────────────────────────────────────────────────────────
# 🛠️ 6. Funciones para generar tablas

trajectory_labels <- list(
  `5class_cubic_nre_dgcc_model_2011_2023` = c("Consistently lower", "Stable medium", "Stable upper medium", "Deteriorating", "Highest"),
  `4class_quadratic_nre_dgcc_model_2011_2019` = c("Consistently lower", "Stable medium", "Stable upper medium", "Highest"),
  `4class_cubic_nre_drsc_model_2011_2023` = c("Consistently low", "Stable medium", "Increasing", "Highest decreasing"),
  `4class_quadratic_random_effects_prop_drsc_model_2011_2019` = c("Consistently low", "Stable medium", "Recovering", "Highest")
)

create_clean_table <- function(df, model_name) {
  # Check if the model has more than one class
  if (length(unique(df$y.level)) <= 1) {
    warning(paste("Model skipped (only one class):", model_name))
    return(NULL)  # Skip this model
  }
  
  labels <- trajectory_labels[[model_name]]
  
  df_model <- df %>%
    filter(model_name == !!model_name) %>%
    mutate(
      trajectory = factor(y.level, levels = seq_along(labels), labels = labels)
    ) %>%
    select(term, trajectory, RRR_CI) %>%
    pivot_wider(names_from = trajectory, values_from = RRR_CI)
  
  # Mark the last class (reference) as "Ref"
  reference_label <- tail(labels, 1)
  if (!(reference_label %in% names(df_model))) {
    df_model[[reference_label]] <- NA
  }
  df_model <- df_model %>%
    mutate(across(all_of(reference_label), ~ ifelse(is.na(.x), "Ref", .x)))

  df_model <- clean_term_labels(df_model)
  
  return(df_model)
}



add_reference_rows <- function(table) {
  
  class_cols <- names(table)[names(table) != "term"]
  
  ref_rows <- tibble(
    term = c("Urbana (Ref)", "Centro (Ref)")
  )
  
  for (col in class_cols) {
    ref_rows[[col]] <- "Ref"
  }
  
  final_table <- bind_rows(table, ref_rows) %>%
    arrange(factor(term, levels = c(
      "(Intercept)",
      "Deprivation Index (continuous)",
      "Mixta (Ref: Urbana)", "Rural (Ref: Urbana)", "Urbana (Ref)", 
      "Norte (Ref: Centro)", "Sur (Ref: Centro)", "Centro (Ref)"
    )))
  
  return(final_table)
}

# ─────────────────────────────────────────────────────────────────────
# 📊 7. Crear tablas finales
final_table_5class_dgcc <- create_clean_table(final_regression_table, "5class_cubic_nre_dgcc_model_2011_2023") %>% add_reference_rows()
final_table_4class_dgcc <- create_clean_table(final_regression_table, "4class_quadratic_nre_dgcc_model_2011_2019") %>% add_reference_rows()
final_table_4class_drsc <- create_clean_table(final_regression_table, "4class_cubic_nre_drsc_model_2011_2023") %>% add_reference_rows()
final_table_4class_drsc_re <- create_clean_table(final_regression_table, "4class_quadratic_random_effects_prop_drsc_model_2011_2019") %>% add_reference_rows()

final_table_5class_dgcc %>% gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  )  %>% 
  tab_header(
    title = md("**Table S5: Odds ratios and 95% confidence intervals for DGCC 2011-2023 from multinomial logistic regression assessing the association between covariates and membership in the highest latent class compared to other classes.**")
  )

final_table_4class_dgcc %>% gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  )  %>% 
  tab_header(
       title = md("**Table S6: Odds ratios and 95% confidence intervals for DGCC 2011-2019 from multinomial logistic regression assessing the association between covariates and membership in the highest latent class compared to other classes.**")
  )
    
  final_table_4class_drsc %>% gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  )  %>% 
  tab_header(
      title = md("**Table S7: Odds ratios and 95% confidence intervals for DRSC 2011-2023 from multinomial logistic regression assessing the association between covariates and membership in the highest latent class compared to other classes.**")
  )
    
  final_table_4class_drsc_re %>% gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  )  %>% 
 tab_header(
      title = md("**Table S8: Odds ratios and 95% confidence intervals for DRSC 2011-2019 from multinomial logistic regression assessing the association between covariates and membership in the highest latent class compared to other classes.**")
  )
    
    


```

```{r}

extract_estimates_table <- function(model) {
  # Obtener el summary con estimates completos
  model_summary <- summary(model)
  
  if (is.null(model_summary$best)) {
    warning("El modelo no contiene estimates en $best")
    return(NULL)
  }
  
  df <- as.data.frame(model_summary$best)
  
  # Asignar nombres correctos
  colnames(df) <- c("Estimate", "Std.Error", "Wald", "p_value")
  
  df$Signif <- cut(df$p_value,
                   breaks = c(-Inf, 0.01, 0.05, 0.1, Inf),
                   labels = c("***", "**", "*", ""),
                   right = FALSE)
  
  df$Estimate_fmt <- paste0(round(df$Estimate, 4), df$Signif)
  df$Param_Class <- rownames(df)
  
  # Separar en columnas
  df_sep <- df %>%
    mutate(
      Param = sub(" class.*", "", Param_Class),
      Class = sub(".*class", "Class ", Param_Class)
    ) %>%
    select(Param, Class, Estimate_fmt)
  
  # Pivotear a formato ancho
  tabla_final <- pivot_wider(df_sep, names_from = Class, values_from = Estimate_fmt)
  return(tabla_final)
}


```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false




grolts_completed <- tibble::tibble(
  Question = c(
    "1. Is the Metric of Time Used in the Statistical Model Reported?",
    "2. Is Information Presented About the Mean and Variance of Time Within a Wave?",
    "3a. Is the missing data mechanism reported?",
    "3b. Is a description provided of what variables are related to attrition/missing data?",
    "3c. Is a description provided of how missing data in the analyses were dealt with",
    "4. Is information about the distribution of the observed variables included?",
    "5. Is the software mentioned",
    "6a. Are Alternative Specifications of Within-Class Heterogeneity Considered?",
    "6b. Are alternative specifications of Between-Class Differences in variance-covariance matrix structure considered and documented.",
    "7. Are Alternative Shape and Functional Forms of the Trajectories Described?",
    "8. If covariates are used, can analysis still be replicated",
    "9. Is information reported about the number of random start values and final iterations included?",
    "10. Are the model comparison tools used described?",
    "11. Are the Total Number of Fitted Models Reported? Including the One-Class Solution?",
    "12. Are the number of cases per class reported?",
    "13. If classification of cases in a trajectory is the goal, is entropy reported?",
    "14a. Is a plot included with the estimated trajectories for the Final Solution",
    "14b. Are Plots included with the estimated mean trajectories for each model?",
    "14c. Is a Plot Included of the Combination of Estimated Means of the Final Model and Observed Individual Trajectories Split out for Each Latent Class",
    "15. Are the characteristics of the Final Class Solution Numerically Described?",
    "16. Are the syntax files Available?"
  ),
  `Yes/No` = c(
    "Yes", "Yes", "Yes", "Yes", "Yes",
    "Yes", "Yes", "Yes", "Yes", "Yes",
    "Yes", "Yes", "Yes", "Yes", "Yes",
    "Yes", "Yes", "Yes", "Yes", "Yes",
    "Yes"
  ),
  `Section Reported` = c(
    "Methods – Study design and statistical analysis",
    "Methods – Study design",
    "Methods – Missing data handling",
    "Methods – Missing data handling",
    "Methods – Missing data handling",
    "Methods and Results – Covariates description",
    "Methods – Statistical analysis",
    "Methods – Statistical analysis",
    "Methods – Statistical analysis",
    "Methods – Statistical analysis",
    "Methods – Covariate definitions and GitHub link",
    "Methods – Statistical analysis",
    "Methods – Statistical analysis",
    "Methods – Statistical analysis",
    "Results – Model adequacy",
    "Results – Model adequacy",
    "Results – Graphical presentation",
    "Results – Graphical presentation",
    "Results – Graphical presentation",
    "Results – Model adequacy",
    "Methods – Software and GitHub statement"
  ),
  Justification = c(
    "Annual time points from 2011 to 2023 are clearly described as the temporal metric used in the latent class mixed models.",
    "Time is consistent across municipalities as it is yearly data; no variation within waves, but the design clarifies this structure.",
    "Data exclusions are based on administrative rules and design; missing data mechanisms are explicitly described.",
    "Explains exclusion rules and that no variables are directly related to missingness; missingness is structural.",
    "Complete case analysis is performed, with no imputation needed due to curated dataset and exclusions.",
    "Municipal-level covariates are described, summary statistics in each class trajectory by outcome and period is described in tables 1-4 in results section.",
    "R version 4.4.2 and lcmm package version 2.1.0 are reported.",
    "Ten model structures tested with and without random effects and heteroscedasticity.",
    "Model structure and residual envelope diagnostics were used to test class-specific variance assumptions.",
    "Linear, quadratic, and cubic specifications tested and compared using residual patterns and BIC.",
    "All covariates are defined and public; syntax files available via GitHub ensure replicability.",
    "20 random starts and 1000 max iterations are specified.",
    "BIC, entropy, APPA, OCC, and mismatch metrics are used and documented.",
    "The total number of fitted models is reported and includes the one-class solution. Specifically, we tested 10 model structures (Supplementary Table S1), each evaluated across 1 to 7 latent classes, resulting in 70 fitted models per outcome-period combination. The one-class solution (K = 1) served as a reference point for assessing model structure adequacy and was included in residual diagnostics and BIC evaluations. Finally we fitted 278 models - as two of them do not have converged in the shorter period",
    "Minimum class size >2% is stated; class sizes illustrated in figures.",
    "Relative entropy is reported for each final model (0.67–0.85).",
    "Figures 1 and 2 display estimated trajectories for final models.",
    "Plots with 95% predictive intervals are included.",
    "Spaghetti plots included as Supplementary Figure S7.",
    "All adequacy metrics (APPA, OCC, entropy, mismatch) are presented.",
    "All syntax files and documentation are available on GitHub (link provided)."
  )
)

# View the table
grolts_completed %>%
  gt() %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(0),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white"
  )  %>% 
  tab_header(
    title = md("**Supplementary Table S9. Reporting of latent growth modeling approach using the GRoLTS checklist**")
  )




```

```{r}
#| echo: false
#| message: false
#| warning: false
#| paged-print: false
#| fig-align: left

tibble::tibble(
  Step = 1:8,
  `Step description` = c(
    "Scope model by provisionally selecting a plausible number of classes based on available literature and the structure based on plausible clinical patterns.",
    "Refine the model from step 1 to confirm the optimal number of classes, typically testing K=1–7 classes.",
    "Refine optimal model structure from fixed through to unrestricted random effects of the model using the favoured K derived in step 2.",
    "Run model adequacy assessments as described in online supplementary table S3 including posterior probability of assignments (APPA), odds of correct classification (OCC) and relative entropy.",
    "Investigate graphical presentation",
    "Run additional tools to assess discrimination including Degrees of separation (DoS) and Elsensohn’s envelope of residuals",
    "Assess for clinical characterisation and plausibility.",
    "Conduct sensitivity analyses, for example, testing models without complete data at all time points."
  ),
  `Criteria for selection` = c(
    "Examine linearity of the shape of standardised residual plots for each of the classes in a model with no random effects.",
    "Lowest Bayesian information criteria value.",
    "",
    "APPA: average of maximum probabilities should be greater than 70% for all classes.\nOCC values greater than 5.0.\nRelative entropy values greater than 0.5.",
    "Plot mean trajectories across time for each class in a single graph.\nPlot mean trajectories with 95% predictive intervals for each class (one class per graph).\nPlot individual class ‘spaghetti plots’ across time for a random sample.",
    "DoS greater than zero.\nEnvelope of residuals is assessed in plots by observing clear separations between classes.",
    "Tabulation of characteristics by latent classes. Are the trajectory patterns clinically meaningful? Perhaps, consider classes with a minimum percentage of the population.\nAre the trajectory patterns clinically plausible?\nConcordance of class characteristics with those for other well-established variables.",
    "General assessment of patterns of trajectories compared with main model."
  )
) %>%
  gt::gt() %>%
  #tab_spanner(label = 'Model fit and diagnostic criteria', columns = 2:16) %>%
  tab_options(
    table.font.size = 10,
    data_row.padding = px(1),
    table.border.top.color = "black",
    heading.border.bottom.color = "black",
    row_group.border.top.color = "black",
    row_group.border.bottom.color = "white",
    table.border.bottom.color = "white",
    column_labels.border.top.color = "black",
    column_labels.border.bottom.color = "black",
    table_body.border.bottom.color = "black",
    table_body.hlines.color = "white")  %>% 
  tab_header(
    title = md("**Supplementary Table S10. Framework of eight steps to construct a latent class trajectory model**")
  )



```
